{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lKKsyxjO1jiM"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XEE9ecyZ2Vb1"
   },
   "outputs": [],
   "source": [
    "df=pd.read_csv('amazon.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OC604WME2g0f"
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YMj8NatI2hzH"
   },
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AyPT2fZa2lb4"
   },
   "outputs": [],
   "source": [
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kUIkKj8Z23Pq"
   },
   "outputs": [],
   "source": [
    "df[df['rating_count'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Njb7Nhmu3JnV"
   },
   "outputs": [],
   "source": [
    "df.dropna(subset=['rating_count'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lUkNb8UB3VAf"
   },
   "outputs": [],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q9hKOkch3egK"
   },
   "outputs": [],
   "source": [
    "df.duplicated('product_id').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NEPx2Ma73u_g"
   },
   "outputs": [],
   "source": [
    "df['discounted_price'] = df['discounted_price'].astype(str).str.replace('₹', '').str.replace(',', '').astype(float)\n",
    "df['actual_price'] = df['actual_price'].astype(str).str.replace('₹', '').str.replace(',', '').astype(float)\n",
    "df['discount_percentage'] = df['discount_percentage'].astype(str).str.replace('%','').astype(float)/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "37_21N2h34gV"
   },
   "outputs": [],
   "source": [
    " df['rating'].str.contains('\\|').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LMc_RPtc4Q5k"
   },
   "outputs": [],
   "source": [
    "df = df[df['rating'].apply(lambda x: '|' not in str(x))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ADBbt2HZ4C0X"
   },
   "outputs": [],
   "source": [
    "df['rating'].str.contains('\\|').sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rzdIvQSN4LDM"
   },
   "outputs": [],
   "source": [
    "df['rating'] = df['rating'].astype(str).str.replace(',', '').astype(float)\n",
    "df['rating_count'] = df['rating_count'].astype(str).str.replace(',', '').astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y1dBE0mv4aXG"
   },
   "outputs": [],
   "source": [
    "df['rating_weighted'] = df['rating'] * df['rating_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YIKbTKFT4vSV"
   },
   "outputs": [],
   "source": [
    "df['sub_category'] = df['category'].astype(str).str.split('|').str[-1]\n",
    "df['main_category'] = df['category'].astype(str).str.split('|').str[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qewg4EUw43f2"
   },
   "outputs": [],
   "source": [
    "numeric_cols = df.select_dtypes(include=['float64', 'int64'])\n",
    "for col in df.columns:\n",
    "    if df[col].dtype == 'object':\n",
    "        df[col] = df[col].apply(lambda x: x.strip() if isinstance(x, str) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gVK2d9NSgVYz"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qRKfnx2nf9ch"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,3,figsize=(20,8))\n",
    "fig.suptitle('Rating & Amount of Ratings Distribution', fontweight='heavy', size='large')\n",
    "sns.histplot(ax=ax[0],data=df, x='rating', bins=15, kde=True, color='green')\n",
    "sns.histplot(ax=ax[1],data=df, x='rating_count', bins=15, kde=True, color='red')\n",
    "sns.histplot(ax=ax[2],data=df, x='rating_weighted', bins=15, kde=True, color='blue')\n",
    "ax[0].set_xlabel('Ratings')\n",
    "ax[1].set_xlabel('Number of Ratings')\n",
    "ax[2].set_xlabel('Weighted Ratings')\n",
    "\n",
    "ax[0].set_ylabel('Number of Products')\n",
    "ax[1].set_ylabel('Number of Products')\n",
    "ax[2].set_ylabel('Number of Products')\n",
    "\n",
    "ax[0].set_title('Distribution of Ratings', fontweight='bold')\n",
    "ax[1].set_title('Distribution of Count Ratings', fontweight='bold')\n",
    "ax[2].set_title('Distribution of Weighted Ratings', fontweight='bold')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dV4Gpzb8uJIC"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,3,figsize=(20,8))\n",
    "\n",
    "fig.suptitle('Rating & Amount of Ratings Distribution', fontweight='heavy', size='large')\n",
    "\n",
    "sns.boxplot(ax=ax[0],data=df, x='rating',color='blue')\n",
    "sns.boxplot(ax=ax[1],data=df, x='rating_count',  color='red')\n",
    "sns.boxplot(ax=ax[2],data=df, x='rating_weighted', color='green')\n",
    "\n",
    "ax[0].set_xlabel('Ratings')\n",
    "ax[1].set_xlabel('Number of Ratings')\n",
    "ax[2].set_xlabel('Weighted Ratings')\n",
    "\n",
    "ax[0].set_ylabel('Number of Products')\n",
    "ax[1].set_ylabel('Number of Products')\n",
    "ax[2].set_ylabel('Number of Products')\n",
    "\n",
    "ax[0].set_title('Distribution of Ratings', fontweight='bold')\n",
    "ax[1].set_title('Distribution of Count Ratings', fontweight='bold')\n",
    "ax[2].set_title('Distribution of Weighted Ratings', fontweight='bold')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mVza1TsDwLsP"
   },
   "outputs": [],
   "source": [
    "bins = [0, 1, 2, 3, 4, 5] # Define bin edges\n",
    "df['rating_bin'] = pd.cut(df['rating'], bins=bins, include_lowest=True, labels=['0-1', '1-2', '2-3', '3-4', '4-5'])\n",
    "rate_bin = df['rating_bin'].value_counts().reset_index()\n",
    "rate_bin = rate_bin.sort_values('count')\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "\n",
    "sns.barplot(ax=ax,data=rate_bin,x='count',y='rating_bin',order=rate_bin['rating_bin'][::-1],palette='Spectral')\n",
    "ax.bar_label(ax.containers[0])\n",
    "ax.set_xlabel('Count')\n",
    "ax.set_ylabel('Rating Bins')\n",
    "ax.set_title('Number of Ratings by Bins',fontweight='bold',size=16)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S6BfF5U68zEL"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pbU34y-kxvFl"
   },
   "outputs": [],
   "source": [
    "sns.set(style='white',palette=\"icefire\")\n",
    "fig,ax = plt.subplots(figsize=(8,8))\n",
    "sns.boxplot(ax=ax,data=df,x='rating',y='main_category')\n",
    "ax.set_xlabel('Rating')\n",
    "ax.set_ylabel('Main Categories')\n",
    "ax.set_title('Rating by Main Category',fontweight='bold')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aCk7igUYy2zO"
   },
   "outputs": [],
   "source": [
    "mean_top_sub = df.groupby('sub_category')['rating'].mean().sort_values(ascending=False).reset_index()[:15]\n",
    "mean_top_sub['rating'] = np.round(mean_top_sub['rating'],2)\n",
    "low_sub = df.groupby('sub_category')['rating'].mean().sort_values(ascending=True).reset_index()[:10]\n",
    "low_sub['rating'] = np.round(low_sub['rating'],2)\n",
    "\n",
    "fig,ax = plt.subplots(2,1,figsize=(8,8))\n",
    "\n",
    "sns.barplot(ax=ax[0],x='rating', y='sub_category', data=mean_top_sub, palette='coolwarm')\n",
    "sns.barplot(ax=ax[1],x='rating', y='sub_category', data=low_sub, palette='vlag')\n",
    "\n",
    "ax[0].set_xlabel('Mean Rating')\n",
    "ax[0].set_ylabel('Sub Category')\n",
    "ax[0].set_title('Top Rated Sub Categories')\n",
    "ax[0].bar_label(ax[0].containers[0])\n",
    "\n",
    "ax[1].set_xlabel('Mean Rating')\n",
    "ax[1].set_ylabel('Sub Category')\n",
    "ax[1].set_title('Lowest Rated Sub Categories')\n",
    "ax[1].bar_label(ax[1].containers[0])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vV5_n_FTye8B"
   },
   "outputs": [],
   "source": [
    "mean_top = df.groupby('main_category')['rating'].mean().sort_values(ascending=False).reset_index()\n",
    "mean_top['rating'] = np.round(mean_top['rating'],2)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "ax = sns.barplot(x='rating', y='main_category', data=mean_top, palette='viridis')\n",
    "ax.set_xlabel('Mean Rating')\n",
    "ax.set_ylabel('Main Category')\n",
    "ax.set_title('Top Rated by Average Main Categories')\n",
    "ax.bar_label(ax.containers[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ou421ISKhSK0"
   },
   "outputs": [],
   "source": [
    "pairplot = sns.pairplot(numeric_cols, kind='reg',\n",
    "                        plot_kws={'line_kws':{'color':'red'}})\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q39UQfZh5GAo"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_user=LabelEncoder()\n",
    "label_product=LabelEncoder()\n",
    "df['label_user']=label_user.fit_transform(df['user_id'])\n",
    "df['label_product']=label_product.fit_transform(df['product_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uK3dnby7ke0Z"
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ndWd8yJ1k6Ni"
   },
   "outputs": [],
   "source": [
    "df = df.drop_duplicates(subset='label_user', keep='first')\n",
    "df=df.drop_duplicates(subset='label_product', keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zuj6DpKYludf"
   },
   "outputs": [],
   "source": [
    "df['combined_reviews'] = df['review_title'] + \" \" + df['review_content']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "id2CAjbmly1P"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Hc0BMPLqnE71"
   },
   "outputs": [],
   "source": [
    "df['combined_features'] = df['product_name'] + \" \" + df['main_category'] + \" \" + df['sub_category'] + \" \" + df['about_product']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FC-r9xR0nNHL"
   },
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q86Hxo-zd-c2"
   },
   "source": [
    "## function for sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SltrBsBrnmIu"
   },
   "outputs": [],
   "source": [
    "def get_sentiment(text):\n",
    "    te=TextBlob(text)\n",
    "    polority=te.sentiment.polarity\n",
    "    rating=round((polority +1) * 2) +1\n",
    "    return max(min(rating,5),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i8X4oyH2n8oI"
   },
   "outputs": [],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pqb9Pk8EeHrY"
   },
   "source": [
    "### text preprocing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BQ6-eQkenprl"
   },
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "  text=text.lower()\n",
    "  text=re.sub(r'[^\\w\\s]','',text)\n",
    "  tokens=word_tokenize(text)\n",
    "  stopword=set(stopwords.words('english'))\n",
    "  filtered_tokens=[token for token in tokens if token not in stopword]\n",
    "  stemmer=PorterStemmer()\n",
    "  stemmed_tokens=[stemmer.stem(token) for token in filtered_tokens]\n",
    "  preprocessed_text=' '.join(stemmed_tokens)\n",
    "  return preprocessed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ur7K3K7ApJEW"
   },
   "outputs": [],
   "source": [
    "df['preprocessed_combined_reviews'] = df['combined_reviews'].apply(preprocess_text)\n",
    "print(df[['combined_reviews', 'preprocessed_combined_reviews']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JvH9yfVApO62"
   },
   "outputs": [],
   "source": [
    "df['derived_rating'] = df['preprocessed_combined_reviews'].apply(get_sentiment)\n",
    "print(df[['review_content', 'derived_rating']])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hoBy0uzDeTL0"
   },
   "source": [
    "#colabarative filltering using svd++ or matrix factroziation method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T67Y5eXOr3y-"
   },
   "outputs": [],
   "source": [
    "!pip install surprise\n",
    "from surprise import Reader, Dataset\n",
    "from surprise.reader import Reader\n",
    "reader = Reader(rating_scale=(1, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IT6jZjjHqEwm"
   },
   "outputs": [],
   "source": [
    "data=Dataset.load_from_df(df[['label_user','label_product','derived_rating']],reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gDbLGCXIrtdn"
   },
   "outputs": [],
   "source": [
    "# Hyperparameter Tuning\n",
    "param_grid_svdpp = {\n",
    "    'n_epochs': [10, 20, 30, 40, 50],  # Increasing the number of epochs to see if longer training improves results\n",
    "    'n_factors': [20, 50, 100, 200],  # Expanding the range to test smaller and larger spaces of factors\n",
    "    'lr_all': [0.001, 0.003, 0.005, 0.007, 0.01],  # Adding a lower learning rate for finer adjustments\n",
    "    'reg_all': [0.01, 0.02, 0.05, 0.1]  # Adjusting regularization to capture both underfitting and overfitting scenarios\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WopN6TwNsuJY"
   },
   "outputs": [],
   "source": [
    "from surprise.model_selection import GridSearchCV  # Import GridSearchCV\n",
    "from surprise import SVDpp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k-B1l_yWshEM"
   },
   "outputs": [],
   "source": [
    "gs_svdpp = GridSearchCV(SVDpp, param_grid_svdpp, measures=['rmse', 'mae'], cv=5)\n",
    "\n",
    "gs_svdpp.fit(data)\n",
    "print('Best SVDpp parameters:', gs_svdpp.best_params['rmse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-XSVziZNt7RO"
   },
   "outputs": [],
   "source": [
    "# Train-test split\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise import accuracy as acc\n",
    "from surprise.accuracy import rmse, mae\n",
    "trainset, testset = train_test_split(data, test_size=0.2, random_state=42)\n",
    "best_svdpp = gs_svdpp.best_estimator['rmse']\n",
    "best_svdpp.fit(trainset)\n",
    "train_predictions_svdpp = best_svdpp.test(trainset.build_testset())\n",
    "print('Training Set - SVDpp RMSE:', acc.rmse(train_predictions_svdpp))\n",
    "print('Training Set - SVDpp MAE:', acc.mae(train_predictions_svdpp))\n",
    "test_predictions_svdpp = best_svdpp.test(testset)\n",
    "print('Testing Set - SVDpp RMSE:', acc.rmse(test_predictions_svdpp))\n",
    "print('Testing Set - SVDpp MAE:', acc.mae(test_predictions_svdpp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A3ALAchftf01"
   },
   "outputs": [],
   "source": [
    "metrics = {\n",
    "    'SVDpp': {'RMSE': rmse(test_predictions_svdpp), 'MAE': mae(test_predictions_svdpp)}\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2o_BiKjMygJo"
   },
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xQtZeRXPueo3"
   },
   "outputs": [],
   "source": [
    "\n",
    "user_id = 667\n",
    "top_n = 5\n",
    "item_ids = list(trainset.all_items())\n",
    "user_id = 667\n",
    "top_n = 5\n",
    "item_ids = list(trainset.all_items())\n",
    "user_ratings_sorted = []\n",
    "for item_id in item_ids:\n",
    "    prediction = best_svdpp.predict(user_id, item_id)\n",
    "    user_ratings_sorted.append((item_id, prediction.est, prediction.est))\n",
    "user_ratings_sorted = sorted(user_ratings_sorted, key=lambda x: x[1], reverse=True)\n",
    "recommended_items = [(item_id, score) for item_id, _, score in user_ratings_sorted[:top_n]]  # Extract item ID and score\n",
    "\n",
    "# Convert recommendations to DataFrame\n",
    "collab_recom = pd.DataFrame(recommended_items, columns=['Item ID Encoded', 'Score'])\n",
    "\n",
    "print(f\"Top {top_n} Recommendations for User {user_id}:\")\n",
    "print(\"--------------------------------------------\")\n",
    "print(collab_recom)\n",
    "recommended_items = [(item_id, score) for item_id, _, score in user_ratings_sorted[:top_n]]  # Extract item ID and score\n",
    "\n",
    "# Convert recommendations to DataFrame\n",
    "collab_recom = pd.DataFrame(recommended_items, columns=['Item ID Encoded', 'Score'])\n",
    "\n",
    "print(f\"Top {top_n} Recommendations for User {user_id}:\")\n",
    "print(\"--------------------------------------------\")\n",
    "print(collab_recom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uDRXdCmLfCzM"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fOt5bG7CfHP_"
   },
   "source": [
    "#**content based filtering using tfifdf**\n",
    "\n",
    "> Add blockquote\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WJkgaW4zvAcu"
   },
   "outputs": [],
   "source": [
    "def recommend_products(df, user_id_encoded):\n",
    "    tfidf = TfidfVectorizer(stop_words='english')\n",
    "    df['combined_features'] = df['combined_features'].fillna('')  # fill NaN values with empty string\n",
    "    tfidf_matrix = tfidf.fit_transform(df['combined_features'])\n",
    "\n",
    "    user_history = df[df['label_user'] == user_id_encoded]\n",
    "\n",
    "    if not user_history.empty:\n",
    "        indices = user_history.index.tolist()\n",
    "        cosine_sim_user = cosine_similarity(tfidf_matrix[indices], tfidf_matrix)\n",
    "        flat_cosine_sim = cosine_sim_user.flatten()\n",
    "        top_indices = sorted(((i, sim) for i, sim in enumerate(flat_cosine_sim) if i not in indices), key=lambda x: x[1], reverse=True)\n",
    "        top_products = top_indices[:5]\n",
    "        recommended_products = df.iloc[[i[0] for i in top_products]]\n",
    "        results_df = pd.DataFrame({\n",
    "            'Id Encoded': [user_id_encoded] * 5,\n",
    "            'Product ID': recommended_products['product_id'].tolist(),\n",
    "            'Item ID Encoded': recommended_products['label_product'].tolist(),\n",
    "            'Recommended Product': recommended_products['product_name'].tolist(),\n",
    "            'Score Recommendation': [i[1] for i in top_products]\n",
    "        })\n",
    "\n",
    "        return results_df\n",
    "    else:\n",
    "        print(\"No purchase history found.\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FqJiAJ70yUDd"
   },
   "outputs": [],
   "source": [
    "content = recommend_products(df, 141)\n",
    "content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LCkw8hNyfU6D"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B8m0iPmA-eZf"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_H2cdYG7feNn"
   },
   "source": [
    "#**content based  using bert method**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qUx86oIQyX7W"
   },
   "outputs": [],
   "source": [
    "def recomonds_products_bert(df,user_id_encoded):\n",
    "  model=SentenceTransformer('all-MiniLM-L6-v2')\n",
    "  df['combined_features']=df['combined_features'].fillna('')\n",
    "  sentence_embeddings=model.encode(df['combined_features'].tolist(),convert_to_tensor=True)\n",
    "  user_history=df[df['label_user']==user_id_encoded]\n",
    "  if not user_history.empty:\n",
    "    indices=user_history.index.tolist()\n",
    "    user_embeddings=sentence_embeddings[indices]\n",
    "    cosine_sim_user=cosine_similarity(user_embeddings,sentence_embeddings)\n",
    "    flat_cosine_sim=cosine_sim_user.flatten()\n",
    "    top_indices=sorted(((i,sim) for i,sim in enumerate(flat_cosine_sim) if i not in indices),key=lambda x:x[1],reverse=True)\n",
    "    top_products=top_indices[:5]\n",
    "    recommended_products=df.iloc[[i[0] for i in top_products]]\n",
    "    results=pd.DataFrame({\n",
    "        'Id Encoded': [user_id_encoded] * 5,\n",
    "        'Product ID': recommended_products['product_id'].tolist(),\n",
    "        'Item ID Encoded': recommended_products['label_product'].tolist(),\n",
    "        'Recommended Product': recommended_products['product_name'].tolist(),\n",
    "        'Score Recommendation': [i[1] for i in top_products]})\n",
    "    return results\n",
    "  else:\n",
    "    print(\"No purchase history found.\")\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Dzu-n8OoINy2"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mwCxZTV2INde"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ElFUIE2pEZ6H"
   },
   "outputs": [],
   "source": [
    "content =recomonds_products_bert(df, 141) #884\n",
    "content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "17gaCwu0friL"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F4sC8jcUftz_"
   },
   "source": [
    "#**Hybrid method**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "233LbT5RGP20"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "user_factors = best_svdpp.pu  # Array of user latent factors\n",
    "item_factors = best_svdpp.qi  # Array of item latent factors\n",
    "\n",
    "user_id_to_index = trainset._raw2inner_id_users\n",
    "item_id_to_index = trainset._raw2inner_id_items\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "78D7hT86L9nJ"
   },
   "outputs": [],
   "source": [
    "df['user_factors'] = df['label_user'].apply(lambda x: user_factors[user_id_to_index[x]] if x in user_id_to_index else np.zeros(shape=(best_svdpp.n_factors,)))\n",
    "df['item_factors'] = df['label_product'].apply(lambda x: item_factors[item_id_to_index[x]] if x in item_id_to_index else np.zeros(shape=(best_svdpp.n_factors,)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UIw4hYnJLbZd"
   },
   "outputs": [],
   "source": [
    "model = SentenceTransformer('all-MiniLM-L6-v2') # it contain 384 dimmensions\n",
    "\n",
    "descriptions = df['combined_features'].tolist()\n",
    "\n",
    "embeddings = model.encode(descriptions, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IDRUWMu8MX1D"
   },
   "outputs": [],
   "source": [
    "embeddings_df = pd.DataFrame(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EVFW-evVMhAZ"
   },
   "outputs": [],
   "source": [
    "embeddings_df['label_product'] = df['label_product'].values\n",
    "embeddings_df.columns = ['embedding_' + str(i) for i in range(embeddings.shape[1])] + ['label_product']\n",
    "embeddings_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s9rO0YVuM4FR"
   },
   "outputs": [],
   "source": [
    "embeddings_df = pd.merge(embeddings_df, df[['label_product','label_user', 'rating','user_factors','item_factors', 'product_name']], on='label_product', how='left')\n",
    "embeddings_df['user_id_encoded'] = embeddings_df['label_user'].astype(int)\n",
    "embeddings_df['item_id_encoded'] = embeddings_df['label_product'].astype(int)\n",
    "embeddings_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7tw0J9LdcW3p"
   },
   "outputs": [],
   "source": [
    "def hybrid_system(user_id_encoded, df, top_n):\n",
    "    # Find the user index\n",
    "    user_indices = df[df['label_user'] == user_id_encoded].index.tolist()\n",
    "    if not user_indices:\n",
    "        return pd.DataFrame()  # Return an empty DataFrame if user ID is not found\n",
    "    user_index = user_indices[0]\n",
    "\n",
    "    # Extract embeddings and latent factors into numpy arrays\n",
    "    embeddings = np.stack(df[[f'embedding_{i}' for i in range(384)]].values)\n",
    "    item_factors = np.stack(df['item_factors'].values)\n",
    "    user_factors = np.stack(df['user_factors'].values)\n",
    "\n",
    "    # Compute similarity matrices for content-based and collaborative filtering\n",
    "    item_similarity = cosine_similarity(embeddings)\n",
    "    user_item_similarity = cosine_similarity(user_factors, item_factors)\n",
    "    content_scores = item_similarity[user_index]\n",
    "    top_content_indices = np.argsort(-content_scores)[:top_n + 1]  # +1 to possibly exclude the user's own item\n",
    "\n",
    "    # Collaborative filtering: Top N items based on user-item interactions\n",
    "    collaborative_scores = user_item_similarity[user_index]\n",
    "    top_collaborative_indices = np.argsort(-collaborative_scores)[:top_n]\n",
    "\n",
    "    # Combine and deduplicate indices\n",
    "    top_indices = np.unique(np.concatenate([top_content_indices[1:], top_collaborative_indices]))[:top_n]\n",
    "\n",
    "    # Retrieve recommended product details\n",
    "    recommended_products = df.iloc[top_indices]\n",
    "    recommended_products = recommended_products[['label_product', 'product_name', 'rating']]\n",
    "    recommended_products['content_similarity_score'] = content_scores[top_indices]\n",
    "    recommended_products['collaborative_similarity_score'] = collaborative_scores[top_indices]\n",
    "\n",
    "    return recommended_products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d-mun4ZbdZKX"
   },
   "outputs": [],
   "source": [
    "specific_user_id = 664\n",
    "recommended_products = hybrid_system(specific_user_id, embeddings_df, top_n=5)\n",
    "print(recommended_products)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
